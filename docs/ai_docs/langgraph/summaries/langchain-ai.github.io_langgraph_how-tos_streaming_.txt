[How to stream](https://langchain-ai.github.io/langgraph/how-tos/streaming/): LLM should read this page when needing to implement streaming in LangGraph, when troubleshooting streaming issues, or when looking to improve application responsiveness. (This page explains how to stream data from LangGraph using various streaming modes: "values" (all state values), "updates" (node updates only), "debug" (detailed step information), "messages" (LLM tokens), and "custom" (user-defined data). It includes code examples for each streaming mode and how to combine multiple modes.)
